version: '3.8'

services:
  pytorch-ddp:
    build: .
    deploy:
      mode: replicated
      replicas: 3                 # total number of processes = total GPUs
      placement:
        max_replicas_per_node: 2  # master can host 2 containers (2 GPUs)
      resources:
        reservations:
          devices:
            - capabilities: [gpu]  # each container needs 1 GPU
        limits:
          cpus: "12.0" # Headroom for the OS
          memory: 30G # Headroom for the OS
    environment:
      - MASTER_ADDR=master-node-hostname  # replace with master hostname or IP
      - MASTER_PORT=29500
      - WORLD_SIZE=3                      # total DDP processes = total GPUs
      - RANK={{.Task.Slot}}               # Swarm auto assigns ranks 1..3
    volumes:
      - .:/app
    networks:
      - pytorch-network

networks:
  pytorch-network:
    driver: overlay